{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install YOLOv8\n",
    "#!pip install ultralytics\n",
    "#!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Environment info\n",
    "import sys, platform, torch\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}:\", torch.cuda.get_device_name(i))\n",
    "\n",
    "else:\n",
    "    print(\"No CUDA device detected. If you intended to use GPU, check CUDA / driver / torch installation. :contentReference[oaicite:4]{index=4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Quick dataset check (optional visualization)\n",
    "import glob, random, os\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_sample(img_dir, label_dir):\n",
    "    imgs = glob.glob(os.path.join(img_dir, \"*\"))\n",
    "    if not imgs:\n",
    "        print(\"No images in\", img_dir); return\n",
    "    img_path = random.choice(imgs)\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    label_path = os.path.join(label_dir, base + \".txt\")\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    w,h = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path) as f:\n",
    "            for line in f:\n",
    "                cls, xc,yc,ww,hh = map(float, line.strip().split())\n",
    "                xc,yc,ww,hh = xc*w, yc*h, ww*w, hh*h\n",
    "                x0,y0, x1,y1 = xc-ww/2, yc-hh/2, xc+ww/2, yc+hh/2\n",
    "                draw.rectangle([x0,y0,x1,y1], outline=\"red\", width=2)\n",
    "                draw.text((x0, y0), str(int(cls)), fill=\"yellow\")\n",
    "    plt.figure(figsize=(8,6)); plt.imshow(img); plt.axis(\"off\"); plt.show()\n",
    "\n",
    "# Example usage (edit paths if needed)\n",
    "# show_sample(\"./dataset/images/train\", \"./dataset/labels/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c29c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training - adjust epochs as needed, and can reduce batch size if you get oom errors\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# Change as required\n",
    "path = \"C:/Users/ishaa/Desktop/AI_Testing_Ground/Model_Training/ECE4191/datasets/picam-noir-v1-061025/data.yaml\"\n",
    "\n",
    "# Train\n",
    "\n",
    "model.train(\n",
    "    data=path,                      # Path to your dataset YAML file\n",
    "    imgsz=640,                      # Matches your dataset resize\n",
    "    epochs=150,                     # Reasonable for medium dataset\n",
    "    #batch=8,                       # Start with 8; increase to 16 if VRAM allows\n",
    "    batch=-1,                       # Auto-finds max batch size before training\n",
    "    workers=2,                      # Adjust based on CPU cores\n",
    "    device=0,                       # Use GPU 0 (RTX 3060)\n",
    "    half=True,                      # Mixed precision – saves ~30–40% VRAM\n",
    "    optimizer='AdamW',              # Stable and efficient optimizer\n",
    "    patience=30,                    # Early stopping if no improvement\n",
    "    project='runs/train',           # Folder for training runs\n",
    "    name='yolov8s_640_attempt2',   # Custom run name\n",
    "    pretrained=True,                # Use pretrained weights\n",
    "    cache=False,                     # Cache images for faster training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb554bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For resuming model if paused\n",
    "#path_to_last = \"runs/train/yolov8s_640_attempt2/weights/last.pt\"\n",
    "#model = YOLO(path_to_last)  # path to your last checkpoint\n",
    "#model.train(resume=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Evaluate model\n",
    "metrics = model.val()  # runs validation\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — Export model for deployment\n",
    "# Options: 'onnx', 'torchscript', 'tflite', 'engine' (TensorRT), etc.\n",
    "model.export(format=\"onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18109ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLOv8n model\n",
    "#model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Display model information (optional)\n",
    "#model.info()\n",
    "\n",
    "# Train the model on the COCO8 example dataset for 100 epochs\n",
    "#results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)\n",
    "\n",
    "# Run inference with the YOLOv8n model on the 'bus.jpg' image\n",
    "#results = model(\"path/to/bus.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece4179stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
